# -*- coding: utf-8 -*-
"""
Created on Sat May 29 18:11:55 2021

Definitions of variables and vocabulary
Vocabulary and variables attempt to match the original paper

Concept class: an array of shape (k,p) where k is the number of 
    instances in the concept class. The total number of instances is equal
    to the total number of 'concepts'. A bag contains multiple concepts.
    If each bag contains the same number of instances, then 
    k = n_bags * n_instances_per_bag
    
Bag: Text

Euclidean distance: The distance between two vectors

RBF (radial basis function) distance: This is basically the exponential of the 
    euclidean distance

Gaussian Distance: A function of the form a * exponential( -(x-b)**2 / (2*c**2))
    It is basically the exponentail of the squarred euclidean distance

Most likely estimator: The most likely estimator is a similarity measure 
    between the entire concept class C and a bag B
    C = {x^k : k=1, ..., n_instances}
    B = {x_j : j=1, ..., bag_size}
    Note: this is the estimator that maximizes the diverse density
    of a concept DD(t)

embedding (of a single bag): (np.ndarray) size (k,1) where k is the number of 
    concepts in the concept class. The kth feature in the concept class 
    realizes the kth row of the matrix. This verbiage represents the 
    embedding of a SINGLE bag
    
embedding (of all bags): (np.ndarray) size (k, i) where k is the number of 
    concepts in the concept class, and i is the total number of bags being 
    embedded. Each column in the array represents a bag,
    and the kth feature in the concept class realizes the kth row of the 
    matrix.

concept_class: (np.ndarray) of shape (k,p) where k is the number of 
    instances in the concept class, and p is the feature space of an instance. 
    The total number of instances is equal
    to the total number of 'concepts'. A bag contains multiple concepts.
    If each bag contains the same number of instances, then 
    k = n_bags * n_instances_per_bag.  The number of instances per bag can vary
    
bags: (np.ndarray) shape (i,j,p) where n is the number of bags, j is the 
    number of instances per bag, and p is the feature space per instance 
    in a bag
    
sigma: (float) Scaling factor, try values in the range (0 -> 5)
 
@author: vorst
"""

# Python imports
from typing import Union

# Third party imports
import numpy as np

# Local imports

#%%

def euclidean_distance(v1: np.ndarray, 
                       v2: np.ndarray=0) -> float:
    """Eucildean distance 
    $|v1 - v2|^2$
    inputs
    -------
    v1, v2: (np.ndarray)
    outputs
    -------
    distance: (float) distance between two vectors
    
    """
    return np.sqrt(np.sum((v1 - v2)**2))



def gaussian_distance(v1: np.ndarray, 
                      v2: np.ndarray, 
                      gamma: float=1) -> float:
    """
    Gaussian distance function
    """
    return np.exp(-gamma * euclidean_distance(v1, v2)**2)
    


def radial_basis_function_distance(v1: np.ndarray, 
                                   v2: np.ndarray, 
                                   gamma: float=1) -> float:
    r"""
    The Gaussian RBF kernel 
    $exp (\gama ||v1 - v2||^2)$.
    """
    
    return np.exp(-gamma * euclidean_distance(v1, v2))



def most_likely_estimator(concept: np.ndarray, 
                          bag: np.ndarray, 
                          sigma: float,
                          distance: str='euclidean') -> float:
    """The most likely estimator is a similarity measure between the 
    entire concept class C and a bag B
    C = {x^k : k=1, ..., n}
    B = {x_j : j=1, ..., bag_size}
    Note: this is the estimator that maximizes the diverse density
    of a concept DD(t)
    
    This most likeley estimator is the maximum exponential
    of the norm between a bag instance and target concept
    inputs
    -------
    concept: (np.ndarray) of shape (1,p) where p is the number of instances
        in the concept class
    bag: (np.ndarray) of shape (j,p) where j is the number of instances in 
        a bag, and p is the instance space of a bag
    sigma: (float) regularization paramter
    """
    
    if distance == 'euclidean':
        similarity = np.exp(
            -1 * np.square(
                np.linalg.norm(bag - concept, axis=1)) / 
            (sigma ** 2)
            );
    elif distance == 'rbf':
        raise NotImplementedError("Other distance functions are not implemented");
    elif distance == 'rbf2':
        raise NotImplementedError("Other distance functions are not implemented");
    elif distance == 'gaussian':
        raise NotImplementedError("Other distance functions are not implemented");
    else:
        raise NotImplementedError("Other distance functions are not implemented");
    
    return max(similarity)


def embed_bag(concept_class: np.ndarray, 
              bag: np.ndarray, 
              sigma: float,
              distance: str='euclidean') -> np.ndarray:
    """Embed a bag onto a concept class (A concept class is a set of instances)
    inputs
    -------
    concept_class: (np.ndarray)
    bag: (np.ndarray) of shape (j,p) where j is the number of instances in 
        a bag, and p is the instance space of a bag
    sigma: (float) regularization paramter
    distance: (str) 'euclidean' is the only supported distance metric
    outputs
    -------
    embedding: (np.ndarray) size (k,1) where k is the number of concepts in
        the concept class. Each column represents a bag, and the kth feature 
        in the concept class realizes the kth row of the matrix
        """
    
    embedded_bag = np.zeros((concept_class.shape[0]))
        
    for n in range(0, embedded_bag.shape[0]):
        # Calculate similarity measure for each training instance
        embedded_bag[n] = most_likely_estimator(concept_class[n],
                                                bag,
                                                sigma,
                                                distance);
    
    return embedded_bag


def embed_all_bags(concept_class: np.ndarray,
                   bags: Union[np.ndarray, list],
                   sigma: float,
                   distance: str='euclidean') -> np.ndarray:
    """Embed a set of bags onto a concept class (A concept class is a set of 
    instances)
    inputs
    -------
    concept_class: (np.ndarray) of shape (k,p) where k is the number of 
        instances in the concept class. The total number of instances is equal
        to the total number of 'concepts'. A bag contains multiple concepts.
        If each bag contains the same number of instances, then 
        k = n_bags * n_instances_per_bag
    bags: (np.ndarray) shape (i,j,p) where n is the number of bags, j is the 
        number of instances per bag, and p is the feature space per instance 
        in a bag
        (list) of numpy arrays, shape (j,P)
    sigma: (float) Scaling factor, try values in the range (0 -> 5). 
        Low values greatly penalize the dissimilarity between the concept class 
        and bag.
        High values allow tolerance between the concept class and bags
    outputs
    -------
    embedding: (np.ndarray) size (k,l) where k is the number of concepts in
        the concept class, and l is the number of bags being embedded. Each column 
        represents a bag, and the kth feature in the concept class realizes the kth 
        row of the matrix
    """
    
    if not concept_class.ndim == 2:
        msg=("Expecting array of shape (k,p) with 2 dimensions. " +
             "Got {} dimensions")
        raise ValueError(msg.format(concept_class.ndim))

    if hasattr(bags, 'ndim'):
        if not bags.ndim == 3:
            msg=("Expecting bags array of shape (i,j,p) with 3 dimensions. " + 
                 "Got {} dimensions")
            raise ValueError(msg.format(bags.ndim))
            
    if not isinstance(concept_class, np.ndarray):
        msg=("Expecting dense numpy array. Got {}".format(type(concept_class)))
        raise ValueError(msg)
    
    # Embed all bags using all training instances
    if hasattr(bags, 'shape'):
        embedded_bags = np.zeros((concept_class.shape[0], bags.shape[0]))
    # List of bags
    elif hasattr(bags, '__len__'):
        embedded_bags = np.zeros((concept_class.shape[0], len(bags)))
    # Iterate through list or slices of numpy array
    for i, bag in enumerate(bags):
        embedded_bags[:,i] = embed_bag(concept_class, bag, sigma, distance)
    
    return embedded_bags


#%% Testing

def generate_dummy_data(bag_size: int, 
                        n_positive_bags: int, 
                        n_negative_bags: int) -> tuple([np.ndarray, np.ndarray]):
    """A bag is labeled positive if it contains instances from at 
    least two different distributions among N1, N2, and N3"""
    
    print("A bag is labeled positive if it contains instances from at "\
          "least two different distributions among N1, N2, and N3")
    n = [([5,5], [1,1]),
        ([5,-5], [1,1]),
        ([-5,5], [1,1]),
        ([-5,-5], [1,1]),
        ([0,0], [1,1]),]
        
    BAG_SIZE = bag_size
    INSTANCE_SPACE = 2
    N_POSITIVE_BAGS = n_positive_bags
    positive_bags = np.zeros((N_POSITIVE_BAGS, BAG_SIZE, INSTANCE_SPACE))
    N_NEGATIVE_BAGS = n_negative_bags
    negative_bags = np.zeros((N_NEGATIVE_BAGS, BAG_SIZE, INSTANCE_SPACE))
    
    for i in range(0, N_POSITIVE_BAGS):
        
        # Fill with 2 instances from positive distribution    
        distributions = np.random.randint(0, 100, BAG_SIZE)
        positive_bags[i,0,:] = np.random.normal(n[distributions[0] % 3][0], # Mean 
                                                n[distributions[0] % 3][1], # Standard Deviation
                                                INSTANCE_SPACE) # Size
        positive_bags[i,1,:] = np.random.normal(n[distributions[1] % 3][0], # Mean 
                                                n[distributions[1] % 3][1], # Standard Deviation
                                                INSTANCE_SPACE) # Size
        
        for j in range(2, BAG_SIZE):
            # Fill with instances from any other distribution
            positive_bags[i,j,:] = np.random.normal(n[distributions[j] % 5][0], # Mean 
                                                    n[distributions[j] % 5][1], # Standard Deviation
                                                    INSTANCE_SPACE) # Size
    
    
    for i in range(0, N_NEGATIVE_BAGS):
        # Fill with distributions, but maximum of 1 from n1,n2,n3
        distributions = np.random.randint(0, 100, BAG_SIZE)
        flag = False
        for j in range(0, BAG_SIZE):
            mod = distributions[j] % 5
            if flag:
                # Only allow a single instance from positive distribution
                mod = np.random.randint(3, 5) # 3 or 4
            if mod in [0,1,2]:
                flag = True
            # Fill with instances from any other distribution
            negative_bags[i,j,:] = np.random.normal(n[mod][0], # Mean 
                                                    n[mod][1], # Standard Deviation
                                                    INSTANCE_SPACE) # Size
        
    return positive_bags, negative_bags
