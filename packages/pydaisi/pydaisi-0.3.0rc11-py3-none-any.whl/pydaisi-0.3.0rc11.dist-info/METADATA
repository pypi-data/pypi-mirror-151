Metadata-Version: 2.1
Name: pydaisi
Version: 0.3.0rc11
Summary: A Python interface for the Daisi Platform
Home-page: https://github.com/BelmontTechnology/PyDaisi
Author: Daisi Technology, Inc.
Author-email: eng@daisi.io
License: Apache License 2.0
Keywords: Daisi SDK
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests
Requires-Dist: httpx
Requires-Dist: python-dotenv
Requires-Dist: dill
Requires-Dist: rich
Requires-Dist: requests-toolbelt
Requires-Dist: trio
Requires-Dist: tqdm

# Simples steps for using the PyDaisi SDK

## Preliminary tasks

### Install with PIP

- `pip install pydaisi`

### (Optional) Set your personal access token

Create your personal access token

- Browse to your [Daisi Settings](https://app.daisi.io/settings/personal-access-tokens)

Set it in the environment:

```bash
export DAISI_ACCESS_TOKEN=a1b2c3d4e5f67890abcdef124567890
```

or in a `.env` file:

```bash
DAISI_ACCESS_TOKEN=a1b2c3d4e5f67890abcdef124567890
```

## Using PyDaisi

### Normal calls

You can call the Daisi function, it will run until complete, and the result will be available in the `value` attribute when it has returned.

```python
from pydaisi import Daisi

# instantiate a Daisi object
daisi = Daisi("Titanic Statistics", base_url="https://dev3.daisi.io")
# call a Daisi function. You can also use positional parameters: daisi.median("Age")
med = daisi.median(field="Age")
print(f"Median Age of Titanic Passengers was: {med.value}")
print(f"10th Percentile of Titanic Passengers' Ages was: {daisi.percentile('Age', .1).value}")
```

## Parallel Execution

You may also use helper functions to execute many calls from your synchronous code

```python
from pydaisi import Daisi

with Daisi("Titanic Statistics", base_url="https://dev3.daisi.io") as my_daisi:
    calls = []
    calls.append(my_daisi.mean("Age"))
    calls.append(my_daisi.median("Age"))
    calls.append(my_daisi.percentile("Age"))
    print(Daisi.run_parallel(*calls))
```

## Map Execution

You can pass a list of arguments all at once, to avoid the overhead of multiple requests to the API:

```python
from pydaisi import Daisi

with Daisi("Add Two Numbers", base_url="https://dev3.daisi.io") as my_daisi:
    dbe = my_daisi.map(args_list = [{"firstNumber": 5, "secondNumber": x} for x in range(10)])
    print(dbe.value)
```

## Execution Status

A Daisi's status can be accessed with the `status` property:

```python
from pydaisi import Daisi

with Daisi("Add Two Numbers", base_url="https://dev3.daisi.io") as my_daisi:
    de = my_daisi.compute(firstNumber=5, secondNumber=6)
    print(de.status)
```

## Execution Logs

A Daisi's logs can be accessed with the `logs` property:

```python
from pydaisi import Daisi
import time

with Daisi("Live Logging", base_url="https://dev3.daisi.io") as my_daisi:
    de = my_daisi.live_log_test(firstNumber=5, secondNumber=6, delay=3)
    de.status
    time.sleep(2)
    print(de.logs)
```

## Remote Results

You need not fetch the full data of a Daisi Execution in order to chain it to the computation of another daisi! Consider this example:

```python
from pydaisi import Daisi

# Connect to the Serialization Daisi
d3 = Daisi("Daisi Serialize", base_url="https://dev3.daisi.io")

# Import numpy and define the MapStack class that we will use as an example of custom serialization
import numpy as np

class MapStack:
    def __init__(self, nx, ny):
        self.nx = nx
        self.ny = ny
        self.nb_layers = None
        self.maps = []

    def add_layer(self, map):
        if len(map.shape) == 2 and map.shape[0] == self.ny and map.shape[1] == self.nx:
            self.maps.append(map)
            self.nb_layers = len(self.maps)
            return "Map sucessfully added."
        else:
            return "Could not add map. Incompatible dimensions."

# Initialize a new MapStack object with 10 layers
nx = 200
ny = 200
ms = MapStack(nx, ny)
for i in range(10):
    ms.add_layer(np.random.rand(nx, ny))

# Compute the daisi, adding a new layer
d3_execution = d3.compute(map_stack=ms, map=np.random.rand(nx, ny))
d3_execution.value_id

# Compute the daisi, adding a another new layer
d3_execution2 = d3.compute(map_stack=d3_execution, map=np.random.rand(nx, ny))
d3_execution2.value
```
