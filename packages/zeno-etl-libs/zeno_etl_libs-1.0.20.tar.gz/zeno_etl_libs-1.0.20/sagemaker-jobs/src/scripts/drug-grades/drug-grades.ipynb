{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ea3c2e-bff7-4157-b56f-4d1be91787a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../../../..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02ae86a-4c82-46f8-b72e-9831f8ce3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from zeno_etl_libs.logger import get_logger\n",
    "from zeno_etl_libs.db.db import DB\n",
    "from zeno_etl_libs.helper.aws.s3 import S3\n",
    "from zeno_etl_libs.helper import helper\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from zeno_etl_libs.helper.google.sheet.sheet import GoogleSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724df049-6cf0-4501-9166-cc21c110f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.tz import gettz\n",
    "import gc\n",
    "from zeno_etl_libs.django.api import Sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c90779-6682-4956-a618-a31509f6a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import typing\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff7f8cb5-1c92-42b0-b5d0-b67dad60ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = 'dev'\n",
    "datem = ''\n",
    "sqlwrite = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fcaf2c-8c0a-4311-a469-f54e5174032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['env'] = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c420a8-2c4a-45b0-84ad-fbb28098b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "rs_db = DB()\n",
    "rs_db.open_connection()\n",
    "\n",
    "s3 = S3()\n",
    "\n",
    "schema = 'prod2-generico'\n",
    "table_name = 'drug-grades'\n",
    "table_info = helper.get_table_info(db=rs_db, table_name=table_name, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5da504c-23e0-4796-b274-e37f8aa5e61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 17:08:01,993 - root - INFO - \n",
      "        select\n",
      "            \"bill-id\",\n",
      "            \"patient-id\" ,\n",
      "            \"store-id\" ,\n",
      "            \"store-name\" as \"name\",\n",
      "            \"drug-id\" ,\n",
      "            \"drug-name\" ,\n",
      "            \"type\" ,\n",
      "            \"created-date\" as \"created-at\" ,\n",
      "            NVL(sum(case when \"bill-flag\" = 'gross' then quantity end),\n",
      "            0) as \"sold-quantity\",\n",
      "            NVL(sum(case when \"bill-flag\" = 'return' then quantity end),\n",
      "            0) as \"returned-quantity\",\n",
      "            sum(\"net-quantity\") as \"quantity\",\n",
      "            sum(rate) as \"rate\"\n",
      "        from\n",
      "            \"prod2-generico\".\"sales\"\n",
      "        where\n",
      "            datediff('day','2022-05-17',\n",
      "            \"created-date\") between -2 and -1\n",
      "        group by\n",
      "            \"bill-id\",\n",
      "            \"patient-id\" ,\n",
      "            \"store-id\" ,\n",
      "            \"store-name\",\n",
      "            \"drug-id\" ,\n",
      "            \"drug-name\" ,\n",
      "            \"type\" ,\n",
      "            \"created-date\"\n",
      "        having\n",
      "            sum(\"net-quantity\")>0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if datem=='':\n",
    "    date1=date1 = datetime.date.today().strftime('%Y-%m-%d')\n",
    "    # logger.info('Entry taken from params',str(date1))\n",
    "else:\n",
    "    date1=datem\n",
    "    # logger.info('Selecting the default date as the job run date',str(date1))\n",
    "\n",
    "q_aa = f\"\"\"\n",
    "        select\n",
    "            \"bill-id\",\n",
    "            \"patient-id\" ,\n",
    "            \"store-id\" ,\n",
    "            \"store-name\" as \"name\",\n",
    "            \"drug-id\" ,\n",
    "            \"drug-name\" ,\n",
    "            \"type\" ,\n",
    "            \"created-date\" as \"created-at\" ,\n",
    "            NVL(sum(case when \"bill-flag\" = 'gross' then quantity end),\n",
    "            0) as \"sold-quantity\",\n",
    "            NVL(sum(case when \"bill-flag\" = 'return' then quantity end),\n",
    "            0) as \"returned-quantity\",\n",
    "            sum(\"net-quantity\") as \"quantity\",\n",
    "            sum(rate) as \"rate\"\n",
    "        from\n",
    "            \"prod2-generico\".\"sales\"\n",
    "        where\n",
    "            datediff('day','{date1}',\n",
    "            \"created-date\") between -2 and -1\n",
    "        group by\n",
    "            \"bill-id\",\n",
    "            \"patient-id\" ,\n",
    "            \"store-id\" ,\n",
    "            \"store-name\",\n",
    "            \"drug-id\" ,\n",
    "            \"drug-name\" ,\n",
    "            \"type\" ,\n",
    "            \"created-date\"\n",
    "        having\n",
    "            sum(\"net-quantity\")>0 \n",
    "\"\"\"\n",
    "\n",
    "logger.info(q_aa)\n",
    "\n",
    "df_aa = rs_db.get_df(q_aa)\n",
    "df_aa.columns = [c.replace('-', '_') for c in df_aa.columns]\n",
    "\n",
    "# logger.info('Shape of data',str(df_aa.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e82f5bc-bc16-4adc-b08a-9d754068b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_aa['quantity'].fillna(0,inplace=True)\n",
    "df_aa['rate'].fillna(0,inplace=True)\n",
    "\n",
    "df_aa['value'] = df_aa['rate'] * df_aa['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "898b513f-88ca-43ca-ba16-2c486a877688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 17:10:32,948 - root - INFO - Shape of stores data:(47, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Store opened at\n",
    "# =============================================================================\n",
    "\n",
    "q_bb = \"\"\"\n",
    "        SELECT\n",
    "            \"id\",\n",
    "            datediff('day' ,\n",
    "            \"opened-at\",\n",
    "            '{}') as \"age\"\n",
    "        FROM\n",
    "            \"prod2-generico\".\"stores\"\n",
    "        WHERE\n",
    "            datediff('day' ,\n",
    "            \"opened-at\",\n",
    "            '{}' ) < 180\n",
    "\"\"\".format(date1,date1)\n",
    "\n",
    "df_bb = rs_db.get_df(q_bb)\n",
    "df_bb.columns = [c.replace('-', '_') for c in df_bb.columns]\n",
    "\n",
    "logger.info('Shape of stores data:{}'.format(str(df_bb.shape)))\n",
    "\n",
    "def store_age(df_bb):\n",
    "    if df_bb['age'] >= 90:\n",
    "        return '3-6 month'\n",
    "    else:\n",
    "        return '1-3 month'\n",
    "\n",
    "df_bb['age1'] = df_bb.apply(lambda x: store_age(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "655e6bbd-fed2-48d0-adb6-999154501d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# quantity sold\n",
    "# =============================================================================\n",
    "\n",
    "df_qty = df_aa.groupby(['drug_id', 'store_id'])[['quantity']].sum().reset_index()\n",
    "df_qty1 = df_aa.groupby(['drug_id'])[['quantity']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e391400a-3472-411b-ba8e-7c43d70011cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# revenue\n",
    "# =============================================================================\n",
    "\n",
    "df_revenue = df_aa.groupby(['drug_id', 'store_id'])[['value']].sum().reset_index()\n",
    "df_revenue1 = df_aa.groupby(['drug_id'])[['value']].sum().reset_index()\n",
    "# =============================================================================\n",
    "# no. of bills\n",
    "# =============================================================================\n",
    "df_bills = df_aa.groupby(['drug_id', 'store_id'])[['bill_id']].nunique().reset_index()\n",
    "df_bills1 = df_aa.groupby(['drug_id'])[['bill_id']].nunique().reset_index()\n",
    "# =============================================================================\n",
    "# no. of consumers\n",
    "# =============================================================================\n",
    "df_consumers = df_aa.groupby(['drug_id', 'store_id'])[['patient_id']].nunique().reset_index()\n",
    "df_consumers1 = df_aa.groupby(['drug_id'])[['patient_id']].nunique().reset_index()\n",
    "\n",
    "df_aa['created_at'] = pd.to_datetime(df_aa['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3116655-96fe-40e7-9044-fe57de2540ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# no. of days sold\n",
    "# =============================================================================\n",
    "\n",
    "df_aa['days'] = df_aa['created_at'].dt.date\n",
    "df_days = df_aa.groupby(['drug_id', 'store_id'])[['days']].nunique().reset_index()\n",
    "df_days1 = df_aa.groupby(['drug_id'])[['days']].nunique().reset_index()\n",
    "\n",
    "# =============================================================================\n",
    "# recency (last sold)\n",
    "# =============================================================================\n",
    "\n",
    "days = timedelta(1)\n",
    "period_end_d = pd.to_datetime(date1) - days\n",
    "\n",
    "df_recency = df_aa.groupby(['drug_id', 'store_id'])[['created_at']].max().reset_index()\n",
    "df_recency1 = df_aa.groupby(['drug_id'])[['created_at']].max().reset_index()\n",
    "df_recency['recency'] = (pd.to_datetime(period_end_d) - df_recency['created_at']).dt.days\n",
    "\n",
    "df_recency1['recency'] = (pd.to_datetime(period_end_d) - df_recency1['created_at']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc2ebff4-0133-4fb2-b8a0-13160d4f2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# merge all features\n",
    "# =============================================================================\n",
    "\n",
    "meg = [df_qty, df_revenue, df_bills, df_consumers, df_days, df_recency]\n",
    "df_features = reduce(lambda left, right: pd.merge(left, right, on=[\n",
    "    'drug_id', 'store_id'], how='outer'), meg)\n",
    "del (df_features['created_at'])\n",
    "\n",
    "meg1 = [df_qty1, df_revenue1, df_bills1, df_consumers1, df_days1, df_recency1]\n",
    "df_features1 = reduce(lambda left, right: pd.merge(left, right, on=[\n",
    "    'drug_id'], how='outer'), meg1)\n",
    "del (df_features1['created_at'])\n",
    "\n",
    "df_features = df_features1.append(df_features)\n",
    "\n",
    "df_features['store_id'] = df_features['store_id'].fillna(999)\n",
    "\n",
    "df_features = df_features.reset_index().drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e7d194-6561-4bc4-98ba-63cdaa2695c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# creating standard scaler store wise\n",
    "# =============================================================================\n",
    "\n",
    "temp_normalise = df_features[['store_id', 'quantity', 'value', 'bill_id', 'patient_id', 'days', 'recency']]\n",
    "\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, transform: typing.Callable):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, df):\n",
    "        transformed = self.transform.fit_transform(df.values)\n",
    "        return pd.DataFrame(transformed, columns=df.columns, index=df.index)\n",
    "\n",
    "# This one will apply any sklearn transform you pass into it to a group.\n",
    "\n",
    "df_rescaled = (\n",
    "    temp_normalise.groupby('store_id')\n",
    "        .apply(SklearnWrapper(StandardScaler()))\n",
    "        .drop('store_id', axis=1)\n",
    ")\n",
    "\n",
    "temp2_normalise = df_rescaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5595ae0a-d386-4efc-9f5c-2594e064cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /Users/surbhi/PycharmProjects/etl/etl/sagemaker-jobs/src/tmp/\n",
      "path: /Users/surbhi/PycharmProjects/etl/etl/sagemaker-jobs/src/tmp/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# importing pca_components and appling to scaled data set.\n",
    "# =============================================================================\n",
    "pca_file_name= 'drug_grades/pca_components.csv'\n",
    "pca_file_path= s3.download_file_from_s3(file_name=pca_file_name)\n",
    "\n",
    "pca_components=pd.read_csv(pca_file_path,delimiter=',')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  creating Euclidean Distance Caculator and applyin to nearest cluster\n",
    "# =============================================================================\n",
    "cluster_file_name= 'drug_grades/cluster_centers_1.csv'\n",
    "pca_file_path= s3.download_file_from_s3(file_name=cluster_file_name)\n",
    "\n",
    "cluster_centers_set=pd.read_csv(pca_file_path,delimiter=',')\n",
    "\n",
    "cluster_centers_set = np.array(cluster_centers_set)\n",
    "\n",
    "# Euclidean Distance Caculator\n",
    "def dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40086356-963e-47e8-81ba-51d5a935c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clusters = []\n",
    "\n",
    "test = np.dot(np.array(temp2_normalise), (np.array(pca_components).T))\n",
    "\n",
    "for i in range(len(test)):\n",
    "    distances = dist(np.array(test[i]), (cluster_centers_set))\n",
    "    cluster = np.argmin(distances)\n",
    "    clusters.append(cluster)\n",
    "\n",
    "cluster_df = pd.DataFrame(clusters)\n",
    "cluster_df.columns = ['final_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf3a861e-c47d-4a8a-896e-1a48468fb15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://aws-glue-temporary-921939243643-ap-south-1/drug_grades/2022-05-17-17-16-15.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Summary pivot 1\n",
    "# =============================================================================\n",
    "\n",
    "test_df = pd.DataFrame(test)\n",
    "cluster_lvl_1 = pd.merge(test_df, cluster_df,\n",
    "                         right_index=True, left_index=True)\n",
    "\n",
    "cluster_lvl1_output = pd.merge(cluster_lvl_1, df_features, how='inner',\n",
    "                               left_index=True, right_index=True)\n",
    "\n",
    "cluster_lvl1_output_pivot = cluster_lvl1_output.groupby(['final_cluster', 'store_id'],\n",
    "                                                        as_index=False).agg({'drug_id': ['count'],\n",
    "                                                                             'value': ['sum'],\n",
    "                                                                             'bill_id': ['mean'],\n",
    "                                                                             'patient_id': ['mean'],\n",
    "                                                                             'days': ['mean'],\n",
    "                                                                             'recency': ['mean']}).reset_index(\n",
    "    drop=True)\n",
    "cluster_lvl1_output_pivot.columns = ['_'.join(x) for x in\n",
    "                                     cluster_lvl1_output_pivot.columns.ravel()]\n",
    "\n",
    "\n",
    "cluster_lvl1_output_pivot_name = 'drug_grades/{}.csv'.format(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "\n",
    "# Uploading File to S3\n",
    "s3.save_df_to_s3(df=cluster_lvl1_output_pivot, file_name=cluster_lvl1_output_pivot_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ba6ae2-0bba-400c-9bdd-79d593043907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /Users/surbhi/PycharmProjects/etl/etl/sagemaker-jobs/src/tmp/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# # 2nd level\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# Further split of large cluster\n",
    "# =============================================================================\n",
    "\n",
    "further_split_lvl2 = cluster_lvl1_output[cluster_lvl1_output['final_cluster'] == 0]\n",
    "# change features here if needed\n",
    "further_split_lvl2 = pd.DataFrame(further_split_lvl2[[0, 1, 2, 3]])\n",
    "\n",
    "further_split_lvl2_mat = np.array(further_split_lvl2)\n",
    "\n",
    "cluster2_file_name= 'drug_grades/cluster_centers_2.csv'\n",
    "pca_file_path= s3.download_file_from_s3(file_name=cluster2_file_name)\n",
    "\n",
    "cluster_centers_set2=pd.read_csv(pca_file_path,delimiter=',')\n",
    "\n",
    "cluster_centers_set2 = np.array(cluster_centers_set2)\n",
    "\n",
    "clusters_lvl2 = []\n",
    "\n",
    "for i in range(len(further_split_lvl2)):\n",
    "    distances = dist((further_split_lvl2_mat[i]), (cluster_centers_set2))\n",
    "    clusterlvl2 = np.argmin(distances)\n",
    "    clusters_lvl2.append(clusterlvl2)\n",
    "\n",
    "further_split_lvl2_df = pd.DataFrame(further_split_lvl2)\n",
    "\n",
    "further_split_lvl2_df['final_cluster_lvl2'] = clusters_lvl2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25cbdee8-e8cb-4f76-98fb-8f67e6c45712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://aws-glue-temporary-921939243643-ap-south-1/drug_grades/2022-05-17-17-17-01.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Summary pivot 2\n",
    "# =============================================================================\n",
    "\n",
    "cluster_lvl2_output = pd.merge(cluster_lvl1_output, further_split_lvl2_df[['final_cluster_lvl2']],\n",
    "                               how='inner',\n",
    "                               left_index=True, right_index=True)\n",
    "\n",
    "cluster_lvl2_output_pivot = cluster_lvl2_output.groupby(['final_cluster_lvl2', 'store_id'],\n",
    "                                                        as_index=False).agg({'drug_id': ['count'],\n",
    "                                                                             'value': ['sum'],\n",
    "                                                                             'bill_id': ['mean'],\n",
    "                                                                             'patient_id': ['mean'],\n",
    "                                                                             'days': ['mean'],\n",
    "                                                                             'recency': ['mean']}).reset_index(\n",
    "    drop=True)\n",
    "\n",
    "cluster_lvl2_output_pivot.columns = ['_'.join(x) for x in\n",
    "                                     cluster_lvl2_output_pivot.columns.ravel()]\n",
    "\n",
    "\n",
    "cluster_lvl2_output_pivot_name = 'drug_grades/{}.csv'.format(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "\n",
    "# Uploading File to S3\n",
    "s3.save_df_to_s3(df=cluster_lvl2_output_pivot, file_name=cluster_lvl2_output_pivot_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff4df9dd-9978-404e-8b5e-c65681f562d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Final cluster\n",
    "# =============================================================================\n",
    "\n",
    "cluster_file = cluster_lvl1_output[cluster_lvl1_output['final_cluster'] != 0]\n",
    "\n",
    "final_cluster_file = cluster_file.append(cluster_lvl2_output)\n",
    "\n",
    "final_cluster_file['cluster'] = final_cluster_file['final_cluster'\n",
    "                                ].astype(str) + '_' + final_cluster_file['final_cluster_lvl2'].astype(str)\n",
    "\n",
    "final_output_pivot = final_cluster_file.groupby(['cluster', 'store_id'],\n",
    "                                                as_index=False).agg({'drug_id': ['count'],\n",
    "                                                                     'value': ['sum'],\n",
    "                                                                     'bill_id': ['mean'],\n",
    "                                                                     'patient_id': ['mean'],\n",
    "                                                                     'days': ['mean'],\n",
    "                                                                     'recency': ['mean']}).reset_index(drop=True)\n",
    "\n",
    "final_output_pivot.columns = ['_'.join(x) for x in\n",
    "                              final_output_pivot.columns.ravel()]\n",
    "\n",
    "final_output_pivot['drug%'] = final_output_pivot['drug_id_count'\n",
    "                              ] / final_output_pivot['drug_id_count'].sum()\n",
    "\n",
    "final_output_pivot['spend%'] = final_output_pivot['value_sum'\n",
    "                               ] / final_output_pivot['value_sum'].sum()\n",
    "\n",
    "final_output_pivot['drug%']=final_output_pivot['drug%'].astype('float64')\n",
    "final_output_pivot['spend%']=final_output_pivot['spend%'].astype('float64')\n",
    "\n",
    "final_output_pivot['factor'] = final_output_pivot['spend%'] / final_output_pivot['drug%']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92610ab0-baa5-413c-9b15-9e261cfae997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surbhi/.conda/envs/etl/lib/python3.6/site-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# cluster allocation\n",
    "# =============================================================================\n",
    "\n",
    "new_store = df_bb['id'].values\n",
    "\n",
    "new_store1 = df_bb['id'][df_bb['age1'] == '3-6 month'].values\n",
    "\n",
    "new_store2 = df_bb['id'][df_bb['age1'] == '1-3 month'].values\n",
    "\n",
    "new_store1_cluster = final_cluster_file[final_cluster_file.store_id.isin(new_store1)]\n",
    "\n",
    "new_store2_cluster = final_cluster_file[final_cluster_file.store_id.isin(new_store2)]\n",
    "\n",
    "Enterprise_cluster = final_cluster_file[final_cluster_file.store_id == 999]\n",
    "\n",
    "old_stores_cluster = final_cluster_file[(~final_cluster_file.store_id.isin(new_store)) &\n",
    "                                        (final_cluster_file.store_id != 999)]\n",
    "\n",
    "new_store1_cluster.drop(['cluster'], axis=1, inplace=True)\n",
    "\n",
    "new_store2_cluster.drop(['cluster'], axis=1, inplace=True)\n",
    "\n",
    "new_store1_predict = pd.merge(new_store1_cluster, Enterprise_cluster[['drug_id', 'cluster']], how='left',\n",
    "                              left_on='drug_id', right_on='drug_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aebf1e9-5d5d-4ff6-ba2e-654304cea54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(new_store2)):\n",
    "    Enterprise_temp = Enterprise_cluster.copy()\n",
    "    Enterprise_temp['new_store_id'] = new_store2[i]\n",
    "    if i == 0:\n",
    "        new_store2_predict_data = Enterprise_temp\n",
    "    else:\n",
    "        new_store2_predict_data = new_store2_predict_data.append(Enterprise_temp)\n",
    "\n",
    "new_store2_predict = new_store2_predict_data\n",
    "\n",
    "del new_store2_predict['store_id']\n",
    "\n",
    "new_store2_predict = new_store2_predict.rename({'new_store_id': 'store_id'}, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9240d35-2232-498a-8ccc-6ef6ce683dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://aws-glue-temporary-921939243643-ap-south-1/drug_grades/2022-05-17-17-17-45.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cluster_all = new_store1_predict.append(new_store2_predict)\n",
    "\n",
    "cluster_all = cluster_all.append(Enterprise_cluster)\n",
    "\n",
    "cluster_all = cluster_all.append(old_stores_cluster)\n",
    "\n",
    "# =============================================================================\n",
    "# Summary report\n",
    "# =============================================================================\n",
    "\n",
    "cluster_all_pivote = cluster_all.groupby(['cluster', 'store_id'],\n",
    "                                         as_index=False).agg({'drug_id': ['count'],\n",
    "                                                              'value': ['sum'],\n",
    "                                                              'bill_id': ['mean'],\n",
    "                                                              'patient_id': ['mean'],\n",
    "                                                              'days': ['mean'],\n",
    "                                                              'recency': ['mean']}).reset_index(drop=True)\n",
    "\n",
    "cluster_all_pivote.columns = ['_'.join(x) for x in\n",
    "                              cluster_all_pivote.columns.ravel()]\n",
    "\n",
    "cluster_all_pivote['drug%'] = cluster_all_pivote['drug_id_count'\n",
    "                              ] / cluster_all_pivote['drug_id_count'].sum()\n",
    "\n",
    "cluster_all_pivote['spend%'] = cluster_all_pivote['value_sum'\n",
    "                               ] / cluster_all_pivote['value_sum'].sum()\n",
    "\n",
    "cluster_all_pivote['drug%'] = cluster_all_pivote['drug%'].astype('float64')\n",
    "cluster_all_pivote['spend%'] = cluster_all_pivote['spend%'].astype('float64')\n",
    "\n",
    "cluster_all_pivote['factor'] = cluster_all_pivote['spend%'\n",
    "                               ] / cluster_all_pivote['drug%']\n",
    "\n",
    "\n",
    "cluster_all_pivote_name = 'drug_grades/{}.csv'.format(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "\n",
    "# Uploading File to S3\n",
    "s3.save_df_to_s3(df=cluster_all_pivote, file_name=cluster_all_pivote_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c8c61b1-6e03-43ba-9823-4630de70ce9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://aws-glue-temporary-921939243643-ap-south-1/drug_grades/2022-05-17-17-18-07.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Assigning Cluster\n",
    "# =============================================================================\n",
    "\n",
    "def assign_cluster(cluster_all):\n",
    "    if cluster_all['cluster'] == '1_nan':\n",
    "        return 'A1'\n",
    "    elif cluster_all['cluster'] == '2_nan':\n",
    "        return 'A1'\n",
    "    elif cluster_all['cluster'] == '4_nan':\n",
    "        return 'A2'\n",
    "    elif cluster_all['cluster'] == '0_2.0':\n",
    "        return 'B'\n",
    "    elif cluster_all['cluster'] == '3_nan':\n",
    "        return 'D'\n",
    "    elif cluster_all['cluster'] == '0_0.0':\n",
    "        return 'C'\n",
    "    elif cluster_all['cluster'] == '0_1.0':\n",
    "        return 'C'\n",
    "    else:\n",
    "        return cluster_all['cluster']\n",
    "\n",
    "cluster_all['grade'] = cluster_all.apply(lambda row: assign_cluster(row), axis=1)\n",
    "\n",
    "\n",
    "cluster_all_name = 'drug_grades/{}.csv'.format(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "\n",
    "# Uploading File to S3\n",
    "s3.save_df_to_s3(df=cluster_all, file_name=cluster_all_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "753be61e-33ca-4824-a1a7-b2c394213a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_all_pivote1 = cluster_all.groupby(['grade', 'store_id'],\n",
    "                                          as_index=False).agg({'drug_id': ['count'],\n",
    "                                                               'value': ['sum'],\n",
    "                                                               'bill_id': ['mean'],\n",
    "                                                               'patient_id': ['mean'],\n",
    "                                                               'days': ['mean'],\n",
    "                                                               'recency': ['mean']}).reset_index(drop=True)\n",
    "\n",
    "cluster_all_pivote1.columns = ['_'.join(x) for x in\n",
    "                               cluster_all_pivote1.columns.ravel()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f8422bb-6916-4071-b08b-74923b33d14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://aws-glue-temporary-921939243643-ap-south-1/drug_grades/2022-05-17-17-18-34.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cluster_all_pivote1['drug%'] = cluster_all_pivote1['drug_id_count'\n",
    "                               ] / cluster_all_pivote1['drug_id_count'].sum()\n",
    "\n",
    "cluster_all_pivote1['spend%'] = cluster_all_pivote1['value_sum'\n",
    "                                ] / cluster_all_pivote1['value_sum'].sum()\n",
    "\n",
    "cluster_all_pivote1['drug%'] = cluster_all_pivote1['drug%'].astype('float64')\n",
    "\n",
    "cluster_all_pivote1['spend%'] = cluster_all_pivote1['spend%'].astype('float64')\n",
    "\n",
    "cluster_all_pivote1['factor'] = cluster_all_pivote1['spend%'\n",
    "                                ] / cluster_all_pivote1['drug%']\n",
    "\n",
    "\n",
    "\n",
    "cluster_all_pivote1_name = 'drug_grades/{}.csv'.format(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "\n",
    "# Uploading File to S3\n",
    "s3.save_df_to_s3(df=cluster_all_pivote1, file_name=cluster_all_pivote1_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78e93609-4b4f-4cb3-bab3-baaf02bd01b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surbhi/.conda/envs/etl/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/surbhi/.conda/envs/etl/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "final_data = cluster_all[['store_id', 'drug_id', 'grade']]\n",
    "final_data['calculation_date'] = date1\n",
    "\n",
    "rs_db_write = DB(read_only=False)\n",
    "rs_db_write.open_connection()\n",
    "\n",
    "\n",
    "final_data.columns = [c.replace('_', '-') for c in final_data.columns]\n",
    "final_data['created-at'] = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f96d4268-c6b2-4e1a-8dc4-4f2b540c326f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: {'S': 'ERROR', 'C': '42501', 'M': 'permission denied for relation drug-grades', 'F': '../src/pg/src/backend/catalog/aclchk.c', 'L': '2728', 'R': 'aclcheck_error'}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "{'S': 'ERROR', 'C': '42501', 'M': 'permission denied for relation drug-grades', 'F': '../src/pg/src/backend/catalog/aclchk.c', 'L': '2728', 'R': 'aclcheck_error'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/etl/etl/zeno_etl_libs/db/db.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, params)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/etl/lib/python3.6/site-packages/redshift_connector/cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, args, stream, merge_socket_read)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_socket_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_socket_read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/etl/lib/python3.6/site-packages/redshift_connector/core.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, cursor, operation, vals)\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/etl/lib/python3.6/site-packages/redshift_connector/core.py\u001b[0m in \u001b[0;36mhandle_messages\u001b[0;34m(self, cursor)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: {'S': 'ERROR', 'C': '42501', 'M': 'permission denied for relation drug-grades', 'F': '../src/pg/src/backend/catalog/aclchk.c', 'L': '2728', 'R': 'aclcheck_error'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2c8a3aed5482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m s3.write_df_to_db(df=final_data[table_info['column_name']], table_name=table_name, db=rs_db,\n\u001b[0;32m----> 2\u001b[0;31m                   schema=schema)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m'''getting current grades and replacing them with new if changed'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_drug_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/etl/etl/zeno_etl_libs/helper/aws/s3.py\u001b[0m in \u001b[0;36mwrite_df_to_db\u001b[0;34m(self, df, table_name, db, schema)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"temp_{int(time.time() * 1000)}.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfile_s3_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_df_to_s3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# eg. \"s3://{self.bucket_name}/df.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_to_db_from_s3_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_s3_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_s3_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_s3_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_s3_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/etl/etl/zeno_etl_libs/helper/aws/s3.py\u001b[0m in \u001b[0;36mwrite_to_db_from_s3_csv\u001b[0;34m(self, table_name, file_s3_uri, db, schema)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mMAXERROR\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_df_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/etl/etl/zeno_etl_libs/db/db.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, params)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rollback\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# self.cursor.execute(query)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: {'S': 'ERROR', 'C': '42501', 'M': 'permission denied for relation drug-grades', 'F': '../src/pg/src/backend/catalog/aclchk.c', 'L': '2728', 'R': 'aclcheck_error'}"
     ]
    }
   ],
   "source": [
    "\n",
    "s3.write_df_to_db(df=final_data[table_info['column_name']], table_name=table_name, db=rs_db,\n",
    "                  schema=schema)\n",
    "\n",
    "'''getting current grades and replacing them with new if changed'''\n",
    "new_drug_entries = pd.DataFrame()\n",
    "missed_entries = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29509826-f401-4ccb-8dbe-d97f1ecf6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store_id in final_data['store_id'].unique():\n",
    "    if sqlwrite == 'yes':\n",
    "        if store_id != 999:\n",
    "\n",
    "            current_grade_query = '''\n",
    "                SELECT\n",
    "                    id,\n",
    "                    `store-id`,\n",
    "                    `drug-id`,\n",
    "                    `drug-grade`\n",
    "                FROM `drug-order-info-data`\n",
    "                WHERE `store-id` = {store_id}\n",
    "            '''.format(store_id=store_id)\n",
    "\n",
    "            current_grade = rs_db.get_df(current_grade_query)\n",
    "            current_grade.columns = [c.replace('-', '_') for c in current_grade.columns]\n",
    "\n",
    "            current_grade.columns = list(map(\n",
    "                lambda s: str.replace(s, '-', '_'),\n",
    "                list(current_grade.columns.values)\n",
    "            ))\n",
    "\n",
    "            final_data_store = final_data.loc[\n",
    "                final_data['store_id'] == store_id,\n",
    "                ['store_id', 'drug_id', 'grade']]\n",
    "            grade_joined = current_grade.merge(\n",
    "                final_data_store, on=['store_id', 'drug_id'], how='outer')\n",
    "            grade_joined.loc[grade_joined['grade'].isna(), 'grade'] = 'NA'\n",
    "            new_drug_entries = new_drug_entries.append(\n",
    "                grade_joined[grade_joined['id'].isna()])\n",
    "            grade_joined = grade_joined[~grade_joined['id'].isna()]\n",
    "\n",
    "            grade_joined['change_flag'] = np.where(\n",
    "                grade_joined['drug_grade'] == grade_joined['grade'],\n",
    "                'same', 'changed')\n",
    "\n",
    "            logger.info('Store ' + str(store_id))\n",
    "            logger.info('Total grades calculated' + str(final_data_store.shape[0]))\n",
    "            logger.info('Grades changed' + str(grade_joined[\n",
    "                                                   grade_joined['change_flag'] == 'changed'].shape[0]))\n",
    "\n",
    "            grades_to_change = grade_joined.loc[\n",
    "                grade_joined['change_flag'] == 'changed',\n",
    "                ['id', 'store_id', 'drug_id', 'grade']]\n",
    "            grades_to_change.columns = ['id', 'store_id', 'drug_id', 'drug_grade']\n",
    "            data_to_be_updated_list = list(\n",
    "                grades_to_change[['id', 'drug_grade']].apply(dict, axis=1))\n",
    "\n",
    "            sql = Sql()\n",
    "\n",
    "            sql.update(\n",
    "                {'table': 'DrugOrderInfoData',\n",
    "                 'data_to_be_updated': data_to_be_updated_list}, logger\n",
    "            )\n",
    "\n",
    "            update_test_query = '''\n",
    "                SELECT\n",
    "                    `store-id`,\n",
    "                    `drug-id`,\n",
    "                    `drug-grade`\n",
    "                FROM `drug-order-info-data`\n",
    "                WHERE `store-id` = {store_id}\n",
    "                    and `grade-updated-at` >= CURRENT_TIMESTAMP() - INTERVAL 10 MINUTE\n",
    "                    and `grade-updated-at` < CURRENT_TIMESTAMP()\n",
    "            '''.format(store_id=store_id)\n",
    "\n",
    "            update_test = rs_db.get_df(update_test_query)\n",
    "            update_test.columns = [c.replace('-', '_') for c in update_test.columns]\n",
    "\n",
    "            update_test.columns = list(map(\n",
    "                lambda s: str.replace(s, '-', '_'),\n",
    "                list(update_test.columns.values)\n",
    "            ))\n",
    "            update_test = grades_to_change.merge(\n",
    "                update_test, how='left', on=['store_id', 'drug_id'],\n",
    "                suffixes=('', '_updated'))\n",
    "            mismatch = update_test[\n",
    "                update_test['drug_grade'] != update_test['drug_grade_updated']]\n",
    "            missed_entries = missed_entries.append(mismatch)\n",
    "            logger.info('For store ' + str(store_id) + 'update mismatch count'\n",
    "                        + str(mismatch.shape[0]))\n",
    "\n",
    "\n",
    "new_drug_entries_name = 'drug_grades/{}.csv'.format(new_drug_entries)\n",
    "\n",
    "# Uploading File to S3\n",
    "s3.save_df_to_s3(df=new_drug_entries[\n",
    "    ['store_id', 'drug_id', 'drug_grade']], file_name=new_drug_entries_name)\n",
    "\n",
    "\n",
    "missed_entries_name = 'drug_grades/{}.csv'.format(missed_entries)\n",
    "\n",
    "# Uploading File to S3\n",
    "s3.save_df_to_s3(df=missed_entries, file_name=missed_entries_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e68dd-0a2e-4154-8c80-1e0cefdcdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rs_db.close_connection()\n",
    "\n",
    "rs_db_write.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7c4c9-fded-4bcb-b9c2-dcd6b680ee90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
